from pydantic import BaseModel, Field, field_validator, constr
from typing import List, Optional, Dict, Union, Any, Annotated, Literal
from pydantic.types import PositiveInt
import time
import uuid


class ToolCallFunction(BaseModel):
    name: str = Field(
        description="The name of the function to call.",
    )
    arguments: str = Field(
        description="The arguments to call the function with, as generated by the model in JSON format.",
    )


class ToolCall(BaseModel):
    id: str = Field(
        default_factory=lambda: 'chatcmpl-' + uuid.uuid4().hex,
        description="Unique identifier for the tool call.",
    )
    type: Literal['function'] = Field(
        description="The type of the tool. Currently, only function is supported.",
    )
    function: ToolCallFunction = Field(
        description="Function details if the type is 'function'.",
    )


class ChatCompletionMessage(BaseModel):
    content: Optional[str] = Field(
        default=None,
        description="Content of the message.",
    )
    refusal: Optional[str] = Field(
        default=None,
        description="The refusal message generated by the model.",
    )
    role: str = Field(
        default="user",
        description="The role of the author of this message.",
    )
    annotations: Optional[Any] = Field(
        default=None,
        description="Annotations for the message.",
    )
    audio: Optional[Any] = Field(
        default=None,
        description="data about the audio response from the model.",
    )
    tool_calls: Optional[List[ToolCall]] = Field(
        default=None,
        description="List of tool calls made by the model.",
    )


class Usage(BaseModel):
    completion_tokens: int = Field(
        default=0,
        description="The number of tokens used in the completion.",
    )
    prompt_tokens: int = Field(
        default=0,
        description="The number of tokens used in the prompt.",
    )
    total_tokens: int = Field(
        default=0,
        description="The total number of tokens used (completion + prompt).",
    )
    completion_tokens_details: Any = Field(
        default=None,
        description="Detailed information about the completion tokens.",
    )
    prompt_tokens_details: Any = Field(
        default=None,
        description="Detailed information about the prompt tokens.",
    )


class ChatCompletionChoice(BaseModel):
    finish_reason: Literal['stop', 'length', 'content_filter', 'tool_calls'] = Field(
        description="The reason the model stopped generating tokens.",
    )
    index: PositiveInt = Field(
        description="The index of the choice in the list of choices.",
    )
    logprobs: Optional[Any] = Field(
        default=None,
        description="Log probability information for the choice.",
    )
    message: ChatCompletionMessage = Field(
        description="A chat completion message generated by the model.",
    )


class ChatCompletionResponse(BaseModel):
    choices: List[ChatCompletionChoice] = Field(
        description="List of choices generated by the model.",
    )
    created: int = Field(
        default_factory=lambda: int(time.time()),
        description="The Unix timestamp (in seconds) of when the chat completion was created.",
    )
    id: str = Field(
        default_factory=lambda: 'chatcmpl-' + uuid.uuid4().hex,
        description="Unique identifier for the chat completion.",
    )
    model: str = Field(
        description="The model used to generate the chat completion.",
    )
    object: Literal['chat.completion'] = Field(
        default='chat.completion',
        description="The type of object returned.",
    )
    service_tier: Optional[Literal['auto']] = Field(
        default='auto',
        description="The service tier used for the chat completion.",
    )
    system_fingerprint: str = Field(
        default_factory=lambda: uuid.uuid4().hex,
        description="A unique fingerprint for the system that generated the chat completion.",
    )
    usage: Usage = Field(
        description="Usage statistics for the chat completion.",
    )


class ChatCompletionStreamMessage(BaseModel):
    content: Optional[str] = Field(
        default=None,
        description="Content of the message.",
    )
    refusal: Optional[str] = Field(
        default=None,
        description="The refusal message generated by the model.",
    )
    role: str = Field(
        default="user",
        description="The role of the author of this message.",
    )
    tool_calls: Optional[List['ToolCall']] = Field(
        default=None,
        description="List of tool calls made by the model.",
    )


class ChatCompletionStreamChoice(BaseModel):
    delta: ChatCompletionStreamMessage = Field(
        description="The delta of the message generated by the model.",
    )
    finish_reason: Optional[Literal['stop', 'length', 'content_filter', 'tool_calls']] = Field(
        default=None,
        description="The reason the model stopped generating tokens.",
    )
    index: PositiveInt = Field(
        description="The index of the choice in the list of choices.",
    )
    logprobs: Optional[Any] = Field(
        default=None,
        description="Log probability information for the choice.",
    )


class ChatCompletionStreamResponse(BaseModel):
    choices: List[ChatCompletionStreamChoice] = Field(
        description="List of choices generated by the model.",
    )
    created: int = Field(
        default_factory=lambda: int(time.time()),
        description="The Unix timestamp (in seconds) of when the chat completion was created.",
    )
    id: str = Field(
        default_factory=lambda: 'chatcmpl-' + uuid.uuid4().hex,
        description="Unique identifier for the chat completion.",
    )
    model: str = Field(
        description="The model used to generate the chat completion.",
    )
    object: Literal['chat.completion.chunk'] = Field(
        default='chat.completion.chunk',
        description="The type of object returned.",
    )
    service_tier: Optional[Literal['auto']] = Field(
        default='auto',
        description="The service tier used for the chat completion.",
    )
    system_fingerprint: str = Field(
        default_factory=lambda: uuid.uuid4().hex,
        description="A unique fingerprint for the system that generated the chat completion.",
    )
    usage: Usage = Field(
        description="Usage statistics for the chat completion.",
    )
